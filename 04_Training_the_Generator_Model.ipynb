{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "04 - Training the Generator Model.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayakshanesht/Autonomous_Driving_Lecture_resources/blob/Perception/04_Training_the_Generator_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V--kgo4kcqc-"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN3-P8qQcqdB"
      },
      "source": [
        "import os\n",
        "curr_dir = os.getcwd() + '/New'\n",
        "os.mkdir(curr_dir)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zji0s8XScqdC"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keaumfABcqdD"
      },
      "source": [
        "## GAN Model Synthesizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwetj9GBcqdE"
      },
      "source": [
        "def define_gan(g_model, dis_model):\n",
        "    model = keras.models.Sequential()\n",
        "    dis_model.trainable = False\n",
        "    model.add(g_model)\n",
        "    model.add(dis_model)\n",
        "    #opt = keras.optimizers.adam(learning_rate= 0.0002, beta_1= 0.5)\n",
        "    \n",
        "    model.compile(loss= 'binary_crossentropy',\n",
        "                  optimizer= 'adam')\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGW_fNNJcqdE"
      },
      "source": [
        "## Discriminator and Generator Model Synthesizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmeC6NNcqdE"
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(units= 128 * 7 * 7,\n",
        "                                 input_dim= latent_dim))\n",
        "    model.add(keras.layers.Reshape((7, 7, 128)))\n",
        "    \n",
        "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
        "                                           kernel_size= (4,4),\n",
        "                                           strides= (2,2),\n",
        "                                           padding= 'same'))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
        "                                           kernel_size= (4,4),\n",
        "                                           strides= (2,2),\n",
        "                                           padding= 'same'))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Conv2D(filters= 1,\n",
        "                                  kernel_size= (7,7),\n",
        "                                  activation= 'sigmoid',\n",
        "                                  padding= 'same'))\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRTkDbAEcqdF"
      },
      "source": [
        "def define_discriminator(input_shape= (28,28,1)):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters= 64,\n",
        "                                  strides= (2,2),\n",
        "                                  kernel_size= (3, 3),\n",
        "                                  padding= 'same',\n",
        "                                  input_shape= input_shape))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Conv2D(filters= 64,\n",
        "                                  strides= (2,2),\n",
        "                                  kernel_size= (3, 3),\n",
        "                                  padding= 'same',\n",
        "                                  input_shape= input_shape))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.LeakyReLU(0.2))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(units= 1,\n",
        "                                 activation= 'sigmoid'))\n",
        "    #opt = keras.optimizers.adam(learning_rate= 0.0002, beta_1= 0.5)\n",
        "    model.compile(loss= 'binary_crossentropy', optimizer= 'adam')\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4nyH5JCcqdG"
      },
      "source": [
        "## Generating Real Exampels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7EKV1MzcqdG"
      },
      "source": [
        "def load_mnist_data():\n",
        "    (X_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
        "    X_train = np.expand_dims(X_train, axis= -1).astype('float32') / 255.0\n",
        "    return X_train"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxbjL8lcqdG"
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[ix]\n",
        "    y = np.ones((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO5OmksOcqdH"
      },
      "source": [
        "## Generating Fake Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1sYJMGAcqdH"
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = np.random.randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape((n_samples, latent_dim))\n",
        "    return x_input"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HLMNIgicqdI"
      },
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    X_input = generate_latent_points(latent_dim= latent_dim,\n",
        "                               n_samples= n_samples)\n",
        "    X = g_model.predict(X_input)\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utxRa8itcqdI"
      },
      "source": [
        "## Summarizing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZEPkzawcqdI"
      },
      "source": [
        "def summarize_model(epoch, g_model, d_model, latent_dim, dataset, n_samples= 100):\n",
        "    X_real, y_real = generate_real_samples(dataset= dataset, n_samples= n_samples)\n",
        "    X_fake, y_fake = generate_fake_samples(g_model= g_model,\n",
        "                                           latent_dim= latent_dim,\n",
        "                                           n_samples= n_samples)\n",
        "    \n",
        "    acc_real = d_model.evaluate(X_real, y_real, verbose= 0)\n",
        "    acc_fake = d_model.evaluate(X_fake, y_fake, verbose= 0)\n",
        "    print(f'Epoch: {epoch + 1}, Accuracy on real data: {acc_real}, Accuracy on generated data: {acc_fake}')\n",
        "    save_plot(X_fake, epoch= epoch, n=10)\n",
        "    model_name = f'./New/generator_model_{epoch + 1}.h5'\n",
        "    g_model.save(model_name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28dEFE8QcqdJ"
      },
      "source": [
        "## Plotting the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu0OJXZycqdJ"
      },
      "source": [
        "def save_plot(examples, epoch, n=10):\n",
        "    for i in range(n * n):\n",
        "        plt.subplot(n, n, 1+i)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(examples[i, :, :, 0], cmap= 'gray')\n",
        "    filename = f'./New/generated_plot_epoch{epoch + 1}.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLf7sYeacqdK"
      },
      "source": [
        "## GAN Model Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wFA-43FcqdK"
      },
      "source": [
        "def train_gan(gan_model, g_model, d_model, dataset, latent_dim, epochs= 100, batch_size= 256):\n",
        "    half_batch = int(batch_size / 2)\n",
        "    batch_per_epoch = int(dataset.shape[0]/batch_size)\n",
        "    for i in range(epochs):\n",
        "        for j in range(batch_per_epoch):\n",
        "            # Generating real and fake examples\n",
        "            X_real, y_real = generate_real_samples(dataset= dataset, n_samples= half_batch)\n",
        "            X_fake, y_fake = generate_fake_samples(g_model= g_model,\n",
        "                                                   latent_dim= latent_dim,\n",
        "                                                   n_samples= half_batch)\n",
        "            # Stacking the training datas\n",
        "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
        "            # Training the discriminator mode\n",
        "            d_loss = d_model.train_on_batch(X, y)\n",
        "            \n",
        "            # Generating image from latent space\n",
        "            x_input = generate_latent_points(latent_dim= latent_dim,\n",
        "                                             n_samples= batch_size)\n",
        "            \n",
        "            X_gan = generate_latent_points(latent_dim= latent_dim,\n",
        "                                           n_samples= batch_size)\n",
        "            \n",
        "            y_gan = np.ones((batch_size, 1))\n",
        "            \n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            print(f'Epoch: {i + 1}, batch: {j}/{batch_per_epoch},dloss: {d_loss}, gloss: {g_loss}')\n",
        "            \n",
        "        # Saving the model every once in a while\n",
        "        summarize_model(epoch= i,\n",
        "                        g_model= g_model,\n",
        "                        d_model= d_model,\n",
        "                        dataset= dataset,\n",
        "                        latent_dim= latent_dim)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSfbHvX5cqdL"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_nZmA2ScqdM",
        "outputId": "4dbaab00-6e87-41e9-b03c-0755a6bab440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "latent_dim = 100\n",
        "dataset = load_mnist_data()\n",
        "g_model = define_generator(latent_dim= latent_dim)\n",
        "d_model = define_discriminator()\n",
        "gan_model = define_gan(g_model= g_model, dis_model= d_model)\n",
        "\n",
        "# Training the GAN for MNIST!!\n",
        "train_gan(gan_model= gan_model,\n",
        "          g_model= g_model,\n",
        "          d_model= d_model,\n",
        "          dataset= dataset,\n",
        "          latent_dim= latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch: 1, batch: 0/234,dloss: 0.7065749168395996, gloss: 0.7966371178627014\n",
            "Epoch: 1, batch: 1/234,dloss: 0.6663188934326172, gloss: 0.9014703035354614\n",
            "Epoch: 1, batch: 2/234,dloss: 0.6329704523086548, gloss: 0.9907816648483276\n",
            "Epoch: 1, batch: 3/234,dloss: 0.6092478036880493, gloss: 1.0480209589004517\n",
            "Epoch: 1, batch: 4/234,dloss: 0.597564697265625, gloss: 1.0559232234954834\n",
            "Epoch: 1, batch: 5/234,dloss: 0.5992560386657715, gloss: 1.0096603631973267\n",
            "Epoch: 1, batch: 6/234,dloss: 0.6011124849319458, gloss: 0.9248571395874023\n",
            "Epoch: 1, batch: 7/234,dloss: 0.6152433156967163, gloss: 0.8323049545288086\n",
            "Epoch: 1, batch: 8/234,dloss: 0.626510739326477, gloss: 0.7576434016227722\n",
            "Epoch: 1, batch: 9/234,dloss: 0.6132590770721436, gloss: 0.7128360271453857\n",
            "Epoch: 1, batch: 10/234,dloss: 0.5974831581115723, gloss: 0.6924893260002136\n",
            "Epoch: 1, batch: 11/234,dloss: 0.5715564489364624, gloss: 0.6882953643798828\n",
            "Epoch: 1, batch: 12/234,dloss: 0.5371475219726562, gloss: 0.6937010288238525\n",
            "Epoch: 1, batch: 13/234,dloss: 0.503200352191925, gloss: 0.704136073589325\n",
            "Epoch: 1, batch: 14/234,dloss: 0.4665939211845398, gloss: 0.7186765670776367\n",
            "Epoch: 1, batch: 15/234,dloss: 0.43067115545272827, gloss: 0.731850266456604\n",
            "Epoch: 1, batch: 16/234,dloss: 0.40456700325012207, gloss: 0.7464779019355774\n",
            "Epoch: 1, batch: 17/234,dloss: 0.3769405484199524, gloss: 0.7596540451049805\n",
            "Epoch: 1, batch: 18/234,dloss: 0.3589983582496643, gloss: 0.7701402306556702\n",
            "Epoch: 1, batch: 19/234,dloss: 0.3373963236808777, gloss: 0.7868545055389404\n",
            "Epoch: 1, batch: 20/234,dloss: 0.33126944303512573, gloss: 0.8074406385421753\n",
            "Epoch: 1, batch: 21/234,dloss: 0.3172715902328491, gloss: 0.8376846313476562\n",
            "Epoch: 1, batch: 22/234,dloss: 0.2966674566268921, gloss: 0.870498538017273\n",
            "Epoch: 1, batch: 23/234,dloss: 0.2827104330062866, gloss: 0.9135038256645203\n",
            "Epoch: 1, batch: 24/234,dloss: 0.2663164734840393, gloss: 0.9730473756790161\n",
            "Epoch: 1, batch: 25/234,dloss: 0.24563898146152496, gloss: 1.0492174625396729\n",
            "Epoch: 1, batch: 26/234,dloss: 0.2290346622467041, gloss: 1.143057107925415\n",
            "Epoch: 1, batch: 27/234,dloss: 0.22046515345573425, gloss: 1.232551097869873\n",
            "Epoch: 1, batch: 28/234,dloss: 0.2461462765932083, gloss: 1.2953696250915527\n",
            "Epoch: 1, batch: 29/234,dloss: 0.32733702659606934, gloss: 1.3406424522399902\n",
            "Epoch: 1, batch: 30/234,dloss: 0.4039674401283264, gloss: 1.3848270177841187\n",
            "Epoch: 1, batch: 31/234,dloss: 0.984614372253418, gloss: 1.6071569919586182\n",
            "Epoch: 1, batch: 32/234,dloss: 1.328356146812439, gloss: 1.471630573272705\n",
            "Epoch: 1, batch: 33/234,dloss: 1.1408824920654297, gloss: 1.6982591152191162\n",
            "Epoch: 1, batch: 34/234,dloss: 1.0487924814224243, gloss: 1.7974647283554077\n",
            "Epoch: 1, batch: 35/234,dloss: 0.9857360124588013, gloss: 2.228214979171753\n",
            "Epoch: 1, batch: 36/234,dloss: 0.8920159339904785, gloss: 2.2161526679992676\n",
            "Epoch: 1, batch: 37/234,dloss: 0.9932485222816467, gloss: 2.7159981727600098\n",
            "Epoch: 1, batch: 38/234,dloss: 1.1358935832977295, gloss: 2.3640174865722656\n",
            "Epoch: 1, batch: 39/234,dloss: 1.0825872421264648, gloss: 2.2519989013671875\n",
            "Epoch: 1, batch: 40/234,dloss: 1.120483160018921, gloss: 1.8804504871368408\n",
            "Epoch: 1, batch: 41/234,dloss: 1.0424327850341797, gloss: 1.763129711151123\n",
            "Epoch: 1, batch: 42/234,dloss: 1.037736415863037, gloss: 1.6292707920074463\n",
            "Epoch: 1, batch: 43/234,dloss: 0.9007331728935242, gloss: 1.3908259868621826\n",
            "Epoch: 1, batch: 44/234,dloss: 0.9300789833068848, gloss: 1.2206977605819702\n",
            "Epoch: 1, batch: 45/234,dloss: 0.8122110366821289, gloss: 1.191900610923767\n",
            "Epoch: 1, batch: 46/234,dloss: 0.8831281065940857, gloss: 1.1158452033996582\n",
            "Epoch: 1, batch: 47/234,dloss: 0.7922670841217041, gloss: 0.9680833220481873\n",
            "Epoch: 1, batch: 48/234,dloss: 0.8384274840354919, gloss: 0.8815195560455322\n",
            "Epoch: 1, batch: 49/234,dloss: 0.7923210859298706, gloss: 0.9101320505142212\n",
            "Epoch: 1, batch: 50/234,dloss: 0.7248104214668274, gloss: 0.8921483755111694\n",
            "Epoch: 1, batch: 51/234,dloss: 0.7445957660675049, gloss: 0.9289230704307556\n",
            "Epoch: 1, batch: 52/234,dloss: 0.6765293478965759, gloss: 0.9484022855758667\n",
            "Epoch: 1, batch: 53/234,dloss: 0.7044702768325806, gloss: 0.9637376070022583\n",
            "Epoch: 1, batch: 54/234,dloss: 0.6753292679786682, gloss: 0.9819161891937256\n",
            "Epoch: 1, batch: 55/234,dloss: 0.6841068267822266, gloss: 0.9988643527030945\n",
            "Epoch: 1, batch: 56/234,dloss: 0.6810929775238037, gloss: 0.9851327538490295\n",
            "Epoch: 1, batch: 57/234,dloss: 0.6558147668838501, gloss: 0.9780963659286499\n",
            "Epoch: 1, batch: 58/234,dloss: 0.6769626140594482, gloss: 0.9700788259506226\n",
            "Epoch: 1, batch: 59/234,dloss: 0.6745562553405762, gloss: 0.9781732559204102\n",
            "Epoch: 1, batch: 60/234,dloss: 0.6595960855484009, gloss: 0.9322539567947388\n",
            "Epoch: 1, batch: 61/234,dloss: 0.6747225522994995, gloss: 0.8982757329940796\n",
            "Epoch: 1, batch: 62/234,dloss: 0.6311905384063721, gloss: 0.8941166400909424\n",
            "Epoch: 1, batch: 63/234,dloss: 0.6313676834106445, gloss: 0.8708987236022949\n",
            "Epoch: 1, batch: 64/234,dloss: 0.6423426866531372, gloss: 0.8493984937667847\n",
            "Epoch: 1, batch: 65/234,dloss: 0.6571727991104126, gloss: 0.8154905438423157\n",
            "Epoch: 1, batch: 66/234,dloss: 0.6752924919128418, gloss: 0.8573992252349854\n",
            "Epoch: 1, batch: 67/234,dloss: 0.6384361982345581, gloss: 0.82079017162323\n",
            "Epoch: 1, batch: 68/234,dloss: 0.6460435390472412, gloss: 0.8221231698989868\n",
            "Epoch: 1, batch: 69/234,dloss: 0.6319556832313538, gloss: 0.8073495626449585\n",
            "Epoch: 1, batch: 70/234,dloss: 0.6222383975982666, gloss: 0.8030568361282349\n",
            "Epoch: 1, batch: 71/234,dloss: 0.621256411075592, gloss: 0.827450156211853\n",
            "Epoch: 1, batch: 72/234,dloss: 0.618175745010376, gloss: 0.84233558177948\n",
            "Epoch: 1, batch: 73/234,dloss: 0.5976198315620422, gloss: 0.8605743646621704\n",
            "Epoch: 1, batch: 74/234,dloss: 0.6009035110473633, gloss: 0.8622395992279053\n",
            "Epoch: 1, batch: 75/234,dloss: 0.6164999008178711, gloss: 0.8726662397384644\n",
            "Epoch: 1, batch: 76/234,dloss: 0.5964574813842773, gloss: 0.8623045682907104\n",
            "Epoch: 1, batch: 77/234,dloss: 0.5800081491470337, gloss: 0.8959917426109314\n",
            "Epoch: 1, batch: 78/234,dloss: 0.5943653583526611, gloss: 0.8965141773223877\n",
            "Epoch: 1, batch: 79/234,dloss: 0.5780378580093384, gloss: 0.939138650894165\n",
            "Epoch: 1, batch: 80/234,dloss: 0.5659686326980591, gloss: 0.8985369205474854\n",
            "Epoch: 1, batch: 81/234,dloss: 0.5723997354507446, gloss: 0.9071445465087891\n",
            "Epoch: 1, batch: 82/234,dloss: 0.5496362447738647, gloss: 0.8971947431564331\n",
            "Epoch: 1, batch: 83/234,dloss: 0.5489964485168457, gloss: 0.9251009225845337\n",
            "Epoch: 1, batch: 84/234,dloss: 0.5172821283340454, gloss: 0.8972417116165161\n",
            "Epoch: 1, batch: 85/234,dloss: 0.5420104265213013, gloss: 0.9171959161758423\n",
            "Epoch: 1, batch: 86/234,dloss: 0.5329383611679077, gloss: 0.9033118486404419\n",
            "Epoch: 1, batch: 87/234,dloss: 0.5110963582992554, gloss: 0.9094585180282593\n",
            "Epoch: 1, batch: 88/234,dloss: 0.5308139324188232, gloss: 0.8885005712509155\n",
            "Epoch: 1, batch: 89/234,dloss: 0.5113334655761719, gloss: 0.8911340832710266\n",
            "Epoch: 1, batch: 90/234,dloss: 0.4850599467754364, gloss: 0.9465924501419067\n",
            "Epoch: 1, batch: 91/234,dloss: 0.5077903270721436, gloss: 0.9223993420600891\n",
            "Epoch: 1, batch: 92/234,dloss: 0.49893757700920105, gloss: 0.9280616044998169\n",
            "Epoch: 1, batch: 93/234,dloss: 0.5173864960670471, gloss: 0.9462116956710815\n",
            "Epoch: 1, batch: 94/234,dloss: 0.5162266492843628, gloss: 0.9185287952423096\n",
            "Epoch: 1, batch: 95/234,dloss: 0.5278482437133789, gloss: 0.8508750796318054\n",
            "Epoch: 1, batch: 96/234,dloss: 0.5354108810424805, gloss: 0.8393317461013794\n",
            "Epoch: 1, batch: 97/234,dloss: 0.5896761417388916, gloss: 0.8612514734268188\n",
            "Epoch: 1, batch: 98/234,dloss: 0.5484039187431335, gloss: 0.8299373388290405\n",
            "Epoch: 1, batch: 99/234,dloss: 0.5715014934539795, gloss: 0.7607837915420532\n",
            "Epoch: 1, batch: 100/234,dloss: 0.5702625513076782, gloss: 0.7283598780632019\n",
            "Epoch: 1, batch: 101/234,dloss: 0.5848909020423889, gloss: 0.7615631818771362\n",
            "Epoch: 1, batch: 102/234,dloss: 0.584336519241333, gloss: 0.7527744770050049\n",
            "Epoch: 1, batch: 103/234,dloss: 0.5914102792739868, gloss: 0.7485135793685913\n",
            "Epoch: 1, batch: 104/234,dloss: 0.5449223518371582, gloss: 0.7471431493759155\n",
            "Epoch: 1, batch: 105/234,dloss: 0.5322593450546265, gloss: 0.766629695892334\n",
            "Epoch: 1, batch: 106/234,dloss: 0.5276206731796265, gloss: 0.7729533910751343\n",
            "Epoch: 1, batch: 107/234,dloss: 0.5239570140838623, gloss: 0.8154064416885376\n",
            "Epoch: 1, batch: 108/234,dloss: 0.4860328733921051, gloss: 0.8047070503234863\n",
            "Epoch: 1, batch: 109/234,dloss: 0.5220283269882202, gloss: 0.8949854373931885\n",
            "Epoch: 1, batch: 110/234,dloss: 0.4726296663284302, gloss: 0.8882888555526733\n",
            "Epoch: 1, batch: 111/234,dloss: 0.43106597661972046, gloss: 0.9252565503120422\n",
            "Epoch: 1, batch: 112/234,dloss: 0.4252549409866333, gloss: 0.9716882705688477\n",
            "Epoch: 1, batch: 113/234,dloss: 0.408307284116745, gloss: 1.0872827768325806\n",
            "Epoch: 1, batch: 114/234,dloss: 0.41273176670074463, gloss: 1.1373028755187988\n",
            "Epoch: 1, batch: 115/234,dloss: 0.38297194242477417, gloss: 1.241903305053711\n",
            "Epoch: 1, batch: 116/234,dloss: 0.36852625012397766, gloss: 1.323656678199768\n",
            "Epoch: 1, batch: 117/234,dloss: 0.39333975315093994, gloss: 1.483130693435669\n",
            "Epoch: 1, batch: 118/234,dloss: 0.3669896125793457, gloss: 1.5676120519638062\n",
            "Epoch: 1, batch: 119/234,dloss: 0.36553269624710083, gloss: 1.5892270803451538\n",
            "Epoch: 1, batch: 120/234,dloss: 0.3717736303806305, gloss: 1.62149977684021\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}