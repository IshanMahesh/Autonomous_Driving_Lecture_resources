{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Traffic_sign_classification_VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5/7WKhaAYpm88YB2/Eo+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayakshanesht/Autonomous_Driving_Lecture_resources/blob/Perception/Traffic_sign_classification_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMYX9Kz3yXKr"
      },
      "source": [
        "#import libraries require for traffic sign classification problem\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from glob import glob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrG5Tc_qygrr",
        "outputId": "bc7d8495-4e01-4fb1-b7de-44fe58bd409e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57jHcttQytaj"
      },
      "source": [
        "#load dataset\r\n",
        "#!unzip \"/content/drive/My Drive/Traffic sign classification GTSRB/archive.zip\" -d \"/content/drive/My Drive/Traffic sign classification GTSRB/Data/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISsoWdj9yxrT"
      },
      "source": [
        "#Use Image Generators\r\n",
        "#1. Initialize\r\n",
        "#For Training Data\r\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1.0/255.,\r\n",
        "                                                                  rotation_range=30,\r\n",
        "                                                              \r\n",
        "                                                                  zoom_range=0.2,\r\n",
        "                                                                  horizontal_flip=True,\r\n",
        "                                                                  \r\n",
        "                                                                  fill_mode='nearest',\r\n",
        "                                                                  preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\r\n",
        "\r\n",
        "#For Validation Data\r\n",
        "valid_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1.0/255., preprocessing_function=tf.keras.applications.vgg16.preprocess_input)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR4V40j8y3O0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb97732-51c2-4e25-b638-637ea85e7ab0"
      },
      "source": [
        "#Pass set of images to the generator to generate compatible images for CNN\r\n",
        "trainImageData = train_generator.flow_from_directory(\"/content/drive/My Drive/Traffic sign classification GTSRB/Data/Train/\",\r\n",
        "                                                     batch_size=32,\r\n",
        "                                                     class_mode='categorical',\r\n",
        "                                                     target_size=(224,224))\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 39209 images belonging to 43 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvDYnTjy4Bk"
      },
      "source": [
        "Test_Data=pd.read_csv(\"/content/drive/My Drive/Traffic sign classification GTSRB/Data/Test.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEJxLj38y7UG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b80791-4f1a-47e7-a436-b1880235db14"
      },
      "source": [
        "Test_Data.head"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
              "0         53      54       6       5      48      49       16  Test/00000.png\n",
              "1         42      45       5       5      36      40        1  Test/00001.png\n",
              "2         48      52       6       6      43      47       38  Test/00002.png\n",
              "3         27      29       5       5      22      24       33  Test/00003.png\n",
              "4         60      57       5       5      55      52       11  Test/00004.png\n",
              "...      ...     ...     ...     ...     ...     ...      ...             ...\n",
              "12625     42      41       5       6      37      36       12  Test/12625.png\n",
              "12626     50      51       6       5      45      46       33  Test/12626.png\n",
              "12627     29      29       6       6      24      24        6  Test/12627.png\n",
              "12628     48      49       5       6      43      44        7  Test/12628.png\n",
              "12629     32      31       6       5      27      26       10  Test/12629.png\n",
              "\n",
              "[12630 rows x 8 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dU14bS2y-Sd",
        "outputId": "b74ddd0c-cfcb-403b-8e0f-abf94c6ed317"
      },
      "source": [
        "Test_labels1=Test_Data['ClassId'].values\r\n",
        "#Test_labels=np.array(Test_labels1)\r\n",
        "#from sklearn.preprocessing import LabelBinarizer\r\n",
        "#Label_binarizer=LabelBinarizer()\r\n",
        "#Test_labels_transfromed=Label_binarizer.fit_transform(Test_labels)\r\n",
        "Test_labels_transfromed=np.array(tf.keras.utils.to_categorical(Test_labels1,num_classes=43,dtype=\"float32\"))\r\n",
        "#print(Test_labels_transfromed)\r\n",
        "Test_labels_transfromed.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12630, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEdNC5bzAq2"
      },
      "source": [
        "valid_path = \"/content/drive/My Drive/Traffic sign classification GTSRB/Data/Test/\"\r\n",
        "#Test_images=np.load(\"/content/drive/My Drive/Traffic sign classification GTSRB/Data/Test/\")\r\n",
        "#Test_images = glob(valid_path + '/*/*.png')\r\n",
        "#Test_images4=Test_Data['Path'].values\r\n",
        "Test_images2 = glob(valid_path + '/*.png')\r\n",
        "Test_images5=[]\r\n",
        "import cv2\r\n",
        "for image in Test_images2:\r\n",
        "  #img=cv2.imread(image)\r\n",
        "  img=tf.keras.preprocessing.image.load_img(image, target_size=(224,224))\r\n",
        "  imgArray=tf.keras.preprocessing.image.img_to_array(img)\r\n",
        "  #img2=np.expand_dims(imgArray,axis=0)\r\n",
        "  \r\n",
        "  #img2=cv2.resize(imgArray,dsize=(32,32))\r\n",
        "  \r\n",
        "  Test_images5.append(imgArray)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#plt.imshow(Test_images3[0])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEOCWhItUE6q"
      },
      "source": [
        "Test_images3=np.array(Test_images5)\r\n",
        "Test_images3.shape\r\n",
        "plt.imshow(Test_images3[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIwolbIz2Vu1"
      },
      "source": [
        "validation_data=valid_generator.flow(Test_images3,Test_labels_transfromed, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92v1_P2hT59n"
      },
      "source": [
        "#Test_images3=int(Test_images5)\r\n",
        "#Test_images3.resize(12630,32,32,3)\r\n",
        "#len(Test_images3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1vvUDsnzErs"
      },
      "source": [
        "# Follow the following order when planning to use Transfer Learning with existing CNN architectures\r\n",
        "# 1. VGG16\r\n",
        "# 2. Inceptionv3\r\n",
        "# 3. Resnet50\r\n",
        "# 4. Xception\r\n",
        "# 5. Nasnet --\r\n",
        "# Only applicable if you are not planning to train entire model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqJRt7_bzG0e"
      },
      "source": [
        "vgg = tf.keras.applications.vgg16.VGG16(input_shape=[224,224,3],\r\n",
        "                                        weights=\"imagenet\",\r\n",
        "                                        include_top=False)\r\n",
        "\r\n",
        "\r\n",
        "#To use the existing weights and disable training on VGG object.\r\n",
        "# Ensure all weights are immutable\r\n",
        "\r\n",
        "for layer in vgg.layers:\r\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk3ug7jhzIwd"
      },
      "source": [
        "#Create our FC layer as per our spec\r\n",
        "#Flatten\r\n",
        "flatten = tf.keras.layers.Flatten()\r\n",
        "#we should add few more layers\r\n",
        "#FC layer\r\n",
        "finalLayer1=tf.keras.layers.Dense(256,activation='relu')\r\n",
        "finalLayer2=tf.keras.layers.Dropout(0.4)\r\n",
        "finalLayer3=tf.keras.layers.Dense(128,activation='relu')\r\n",
        "finalLayer4=tf.keras.layers.Dropout(0.3)\r\n",
        "finalLayer5 = tf.keras.layers.Dense(43,activation=\"softmax\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "PkS368_GzLf9",
        "outputId": "9a639a3e-f585-49e0-e8c2-8375dfbd767c"
      },
      "source": [
        "model=tf.keras.models.Sequential([vgg,flatten,finalLayer1,finalLayer2,finalLayer3,finalLayer4,finalLayer5])\r\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-71bbb336a93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalLayer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalLayer2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalLayer3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalLayer4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinalLayer5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8kHzmZJzNT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "042b5fc2-8c14-4990-b179-4d085ca09255"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "            \r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e7f43d69e7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(optimizer='adam',\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR5te1QqzPSV"
      },
      "source": [
        "batch_size=32\r\n",
        "history = model.fit(trainImageData,\r\n",
        "                    validation_data=validation_data,\r\n",
        "                    epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyBCWTrPrcV7"
      },
      "source": [
        "# Save the entire model as a SavedModel.\r\n",
        "#!mkdir -p saved_model\r\n",
        "model.save('saved_model/my_model_VGG16.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOx1bnBKzWls"
      },
      "source": [
        "#deployement\r\n",
        "img=tf.keras.preprocessing.image.load_img(\"/content/drive/My Drive/Traffic sign classification GTSRB/Data/Train/17/00017_00005_00029.png\", target_size=(224,224))\r\n",
        "imgArray=tf.keras.preprocessing.image.img_to_array(img)\r\n",
        "#import numpy as np\r\n",
        "img2=np.expand_dims(imgArray,axis=0)\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.imshow(img)\r\n",
        "model.predict(img2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}